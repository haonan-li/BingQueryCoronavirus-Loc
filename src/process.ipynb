{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set(location)\n",
    "gazetteer = set()\n",
    "with open('../resource/gazetteer.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        gazetteer.add(line.strip().lower())\n",
    "        \n",
    "# Set(common words)\n",
    "common_word = set()\n",
    "with open('../resource/common_word_10000.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        word = line.strip()\n",
    "        common_word.add(word)\n",
    "# Set(location) / Set(common words)\n",
    "for word in common_word:\n",
    "    if word in gazetteer:\n",
    "        gazetteer.remove(word)\n",
    "gazetteer.remove('corona')\n",
    "\n",
    "# Dict[Abbr] -> full name\n",
    "abbr = {}\n",
    "with open('../resource/abbr.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split()\n",
    "        abbr[line[-1]] = ' '.join(line[:-1])\n",
    "\n",
    "# Dict[location] -> country code\n",
    "gazetteer_map = {}\n",
    "with open('../resource/allCountries.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().lower().split('\\t')\n",
    "        if line[2] in gazetteer_map:\n",
    "            if line[-4] > gazetteer_map[line[2]][0]:\n",
    "                gazetteer_map[line[2]] = (line[-4],line[8])\n",
    "        else:\n",
    "            gazetteer_map[line[2]] = (line[-4],line[8])\n",
    "\n",
    "# Dict[country code] -> country \n",
    "country_map = {}\n",
    "with open('../resource/countryInfo.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] != '#':\n",
    "            line = line.lower().split('\\t')\n",
    "            country_map[line[0]] = line[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 1644205\n"
     ]
    }
   ],
   "source": [
    "raw_data = []\n",
    "for fname in sorted(os.listdir('../data/')):\n",
    "    if fname.startswith('QueriesByCountry'):\n",
    "        raw_data.append(pd.read_csv(os.path.join('../data/',fname), sep='\\t'))\n",
    "        df = pd.concat(raw_data, axis=0)\n",
    "print (f'Number of records: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abbr\n",
    "abbr_query_map = {}\n",
    "\n",
    "def check_abbr(x):\n",
    "    if x in abbr_query_map:\n",
    "        return abbr_query_map[x]\n",
    "    xs = x.split()\n",
    "    for i,token in enumerate(xs):\n",
    "        if token in abbr:\n",
    "            xs[i] = abbr[token]\n",
    "    newx = ' '.join(xs)\n",
    "    abbr_query_map[x] = newx\n",
    "    return newx\n",
    "\n",
    "df['Query'] = df['Query'].apply(lambda x: check_abbr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# detect loc\n",
    "loc_query_map = {}\n",
    "def detect_loc(x):\n",
    "    if x in loc_query_map:\n",
    "        return loc_query_map[x]\n",
    "    xs = x.split()\n",
    "    for i in range(len(xs)):\n",
    "        for j in range(len(xs)+1,i,-1):\n",
    "            piece = ' '.join(xs[i:j])\n",
    "            if piece in gazetteer:\n",
    "                loc_query_map[x] = piece\n",
    "                return piece\n",
    "    return None\n",
    "df['Loc'] = df['Query'].apply(lambda x: detect_loc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 1644205\n",
      "Number of records contain location: 823379\n"
     ]
    }
   ],
   "source": [
    "# detelt queries not include location\n",
    "print (f'Number of records: {len(df)}')\n",
    "df = df[~df['Loc'].isnull()]\n",
    "print (f'Number of records contain location: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add country of loc\n",
    "loc_country_map = {}\n",
    "def loc_to_country(x):\n",
    "    if x in loc_country_map:\n",
    "        return loc_country_map[x]\n",
    "    if x in country_map.values():\n",
    "        loc_country_map[x] = x\n",
    "        return x\n",
    "    try:\n",
    "        loc_country_map[x] = country_map[gazetteer_map[x][1]]\n",
    "        return loc_country_map[x]\n",
    "    except:\n",
    "        loc_country_map[x] = None\n",
    "        return None\n",
    "df['LocCountry'] = df['Loc'].apply(lambda x: loc_to_country(x))\n",
    "\n",
    "# Save queries contain location. \n",
    "df.to_csv('../results/QueryContainLoc.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: China                Number of records: 4482\n",
      "Country: Netherlands          Number of records: 3349\n",
      "Country: Brazil               Number of records: 8326\n",
      "Country: Sweden               Number of records: 1475\n",
      "Country: Canada               Number of records: 38027\n",
      "Country: Spain                Number of records: 20739\n",
      "Country: United States        Number of records: 437962\n",
      "Country: Austria              Number of records: 1753\n",
      "Country: Italy                Number of records: 47089\n",
      "Country: Switzerland          Number of records: 4375\n",
      "Country: Australia            Number of records: 15716\n",
      "Country: Germany              Number of records: 46664\n",
      "Country: Mexico               Number of records: 6483\n",
      "Country: Argentina            Number of records: 2234\n",
      "Country: India                Number of records: 9163\n",
      "Country: South Africa         Number of records: 3416\n",
      "Country: Malaysia             Number of records: 1128\n",
      "Country: United Kingdom       Number of records: 79921\n",
      "Country: Belgium              Number of records: 4470\n",
      "Country: Colombia             Number of records: 1355\n",
      "Country: France               Number of records: 66762\n"
     ]
    }
   ],
   "source": [
    "# For queries from each country, split them into batches and count frequency of the location names for each batch\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_word_freq(df,ngram=1):\n",
    "    word_freq = defaultdict(int)\n",
    "    for _,row in df.iterrows():\n",
    "        for word in ngrams(row['Query'].split(), ngram):\n",
    "            word_freq[word] += row['PopularityScore']\n",
    "    word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "    return word_freq\n",
    "\n",
    "def get_trend(country_df, country):\n",
    "    batch = 10\n",
    "    dates = sorted(list(set(country_df['Date'])))\n",
    "    batch_size = len(dates)//batch\n",
    "    batch_dates = [dates[i:i+batch_size] for i in range(0, len(dates), batch_size)][:batch]\n",
    "    \n",
    "    count = []\n",
    "    for cur_batch_dates in batch_dates:\n",
    "        cur_batch_dates = set(cur_batch_dates)\n",
    "        batch_count = defaultdict(int)\n",
    "        cur_df = country_df[country_df['Date'].isin(cur_batch_dates)]\n",
    "        for idx, row in cur_df.iterrows():\n",
    "            batch_count[row['LocCountry']] += row['PopularityScore'] \n",
    "        count.append(batch_count)\n",
    "    return count\n",
    "            \n",
    "\n",
    "trend_by_country = {}\n",
    "for country in set(df['Country']): \n",
    "    country_df = df[df['Country']==country]\n",
    "    # filter the country with few records\n",
    "    if len(country_df) < 1000:\n",
    "        continue\n",
    "    \n",
    "    print (f'Country: {country:20} Number of records: {len(country_df)}') \n",
    "    trend = get_trend(country_df, country)\n",
    "    unigram = get_word_freq(country_df, 1)\n",
    "    bigram = get_word_freq(country_df, 2)\n",
    "    trend_by_country[country] = {'trend':trend, 'unigram':unigram, 'bigram':bigram}\n",
    "    \n",
    "# Save to trend\n",
    "import json\n",
    "with open('../results/trend.json','w') as f:\n",
    "    json.dump(trend_by_country, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Word Count\n",
    "\n",
    "\n",
    "# def output_freq(unigram_freq,bigram_freq,fname):\n",
    "#     with open('unigram_'+fname, 'w') as fout:\n",
    "#         for w,f in unigram_freq:\n",
    "#             fout.write(f\"{' '.join(w):30}\\t{f}\\n\")\n",
    "#     with open('bigram_'+fname, 'w') as fout:\n",
    "#         for w,f in bigram_freq:\n",
    "#             fout.write(f\"{' '.join(w):30}\\t{f}\\n\")\n",
    "                       \n",
    "# unigram_freq = get_word_freq(data,1)\n",
    "# bigram_freq = get_word_freq(data,2)\n",
    "# output_freq(unigram_freq,bigram_freq,fname.lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geonlp]",
   "language": "python",
   "name": "conda-env-geonlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
